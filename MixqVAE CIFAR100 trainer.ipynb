{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from neural import MixqVAE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "SHUFFLE = True\n",
    "NUM_WORKERS = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_loader = data.DataLoader(\n",
    "    datasets.CIFAR100('./data', train=True, transform=transforms.ToTensor(), download=True),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")\n",
    "\n",
    "test_set_loader = data.DataLoader(\n",
    "    datasets.CIFAR100('./data', train=False, transform=transforms.ToTensor(), download=True),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=SHUFFLE,\n",
    "    num_workers=NUM_WORKERS,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Net and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_CHANNELS = 3\n",
    "NUM_HIDDENS = 256\n",
    "NUM_RES_HIDDENS = 64\n",
    "NUM_RES_LAYERS = 4\n",
    "\n",
    "EMBEDDING_DIM = 128\n",
    "BETA = 0.9\n",
    "LMBD = 0.25\n",
    "NUM_ITER = 3\n",
    "NUM_EMBEDDINGS = 1024\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = MixqVAE(\n",
    "    IN_CHANNELS,\n",
    "    NUM_HIDDENS,\n",
    "    NUM_RES_HIDDENS,\n",
    "    NUM_RES_LAYERS,\n",
    "    \n",
    "    EMBEDDING_DIM,\n",
    "    BETA,\n",
    "    LMBD,\n",
    "    NUM_ITER,\n",
    "    NUM_EMBEDDINGS,\n",
    ").to(device)\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    net.load_state_dict(torch.load(open('state_dict.pth', 'rb')))\n",
    "    print('State Dict loaded from \\'state_dict.pth\\'')\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs=10):\n",
    "    print('='*10, end='')\n",
    "    print(' TRAIN', end=' ') \n",
    "    print('='*10, end='\\n\\n')\n",
    "    net.train()\n",
    "\n",
    "    for epoch in range(1, epochs+1):\n",
    "        running_loss = 0\n",
    "\n",
    "        for i, batch in enumerate(train_set_loader, 1):\n",
    "            images, _ = batch\n",
    "            images = images.to(device)\n",
    "            \n",
    "            # Zero grad\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward\n",
    "            encoded, quantized, recon_x = net(images)\n",
    "            # Compute Loss\n",
    "            loss_value = net.loss_function(images, recon_x, encoded, quantized)\n",
    "            running_loss += loss_value.item()\n",
    "            # Backward\n",
    "            loss_value.backward()\n",
    "            # Update\n",
    "            optimizer.step()\n",
    "\n",
    "            if i % 100 == 0:\n",
    "                print(f'==> EPOCH[{epoch}]({i}/{len(train_set_loader)}): LOSS: {loss_value.item()}')\n",
    "            \n",
    "        print(f'=====> EPOCH[{epoch}] Completed: Avg. LOSS: {running_loss/len(train_set_loader)}')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "image, label = test_set_loader.dataset[10]\n",
    "\n",
    "encoded, quantized, recon = net(image.unsqueeze(0))\n",
    "\n",
    "recon = recon[0].squeeze()\n",
    "plt.imshow(recon.detach().numpy(), cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.vq.embeddings.weight[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encodings = torch.zeros(28*28, 128)\n",
    "encodings[14, 12] = 1\n",
    "encodings[32, 1] = 1\n",
    "quantized = encodings @ net.vq.embeddings.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized = quantized.reshape((1, 28, 28, 8)).permute(0, 3, 1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recon = net.decoder(quantized)[0].squeeze()\n",
    "plt.imshow(recon.detach().numpy(), cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = test_set_loader.dataset[20]\n",
    "image = image.view(-1, 28*28).unsqueeze(0)\n",
    "\n",
    "mu, sigma = net.encode(image)\n",
    "z_2 = mu + sigma * torch.rand_like(sigma)\n",
    "\n",
    "recon = net.decode(z_2)\n",
    "print(label)\n",
    "plt.imshow(recon.view(28, 28).detach().numpy(), cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_3 = z_2 - z_1\n",
    "recon = net.decode(z_3)\n",
    "plt.imshow(recon.view(28, 28).detach().numpy(), cmap='Greys');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), open('vqa_state_dict.pth', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
